{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "\n",
    "STOPWORDS = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['Romeo and Juliet',\n",
    "        'Juliet: O happy dagger!',\n",
    "        'Romeo died by dagger.',\n",
    "        '“Live free or die”, that’s the New-Hampshire’s motto.',\n",
    "        'Did you know, New-Hampshire is in New-England.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokenized_text = word_tokenize(text.lower())\n",
    "    cleaned_text = [t for t in tokenized_text if t not in STOPWORDS and re.match('[a-zA-Z\\-][a-zA-Z\\-]{2,}', t)]\n",
    "    return cleaned_text\n",
    "\n",
    "# For gensim we need to tokenize the data and filter out stopwords\n",
    "tokenized_data = []\n",
    "for text in data:\n",
    "    tokenized_data.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['romeo', 'juliet'],\n",
       " ['juliet', 'happy', 'dagger'],\n",
       " ['romeo', 'died', 'dagger'],\n",
       " ['live', 'free', 'die', 'new-hampshire', 'motto'],\n",
       " ['know', 'new-hampshire', 'new-england']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['juliet', 'romeo', 'dagger', 'happy', 'died']...)\n"
     ]
    }
   ],
   "source": [
    "# Build a Dictionary - association word to numeric id\n",
    "dictionary = corpora.Dictionary(tokenized_data)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the collection of texts to a numerical form\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1)], [(0, 1), (2, 1), (3, 1)], [(1, 1), (2, 1), (4, 1)], [(5, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(9, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juliet\n",
      "romeo\n",
      "dagger\n",
      "happy\n",
      "died\n",
      "die\n",
      "free\n",
      "live\n",
      "motto\n",
      "new-hampshire\n",
      "know\n",
      "new-england\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(v) for v in dictionary.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI Model:\n",
      "Topic #0: 0.562*\"new-hampshire\" + 0.397*\"free\" + 0.397*\"die\" + 0.397*\"motto\" + 0.397*\"live\" + 0.164*\"know\" + 0.164*\"new-england\" + -0.000*\"dagger\" + -0.000*\"happy\" + 0.000*\"juliet\"\n",
      "Topic #1: -0.577*\"dagger\" + -0.500*\"romeo\" + -0.500*\"juliet\" + -0.289*\"died\" + -0.289*\"happy\" + -0.000*\"die\" + -0.000*\"live\" + -0.000*\"motto\" + -0.000*\"free\" + -0.000*\"new-hampshire\"\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 2\n",
    "lsi_model = models.LsiModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)\n",
    "print(\"LSI Model:\")\n",
    " \n",
    "for idx in range(NUM_TOPICS):\n",
    "    # Print the first 10 most representative topics\n",
    "    print(\"Topic #%s:\" % idx, lsi_model.print_topic(idx, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new-hampshire', 0.561516668266344),\n",
       " ('free', 0.39705224388040894),\n",
       " ('die', 0.39705224388040894),\n",
       " ('motto', 0.3970522438804089),\n",
       " ('live', 0.3970522438804089),\n",
       " ('know', 0.164464424385935),\n",
       " ('new-england', 0.16446442438593498),\n",
       " ('dagger', -5.499073418846479e-16),\n",
       " ('happy', -4.0592529337857296e-16),\n",
       " ('juliet', 1.7000290064572714e-16)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model.show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
